---
title: "Formstack Page Analysis - Proposed Methodology"
output:
  html_notebook: default
  html_document: default
date: "November 23, 2016"
---

The following will constitute a proposed methodology for the analysis of   data as part of the on-going mass.gov redesign. An understanding of top performing pages and departments, as well as under performing pages and departments, will be critical as content is migrated from the old percussion site to the new drupal site. 

# The Data 

Formstack is a service which allows websites to collect survey responses from users. MassIT uses Formstack to collect simple information from mass.gov visitors concerning their ability to find the information or service they are looking for on a given webpage. The survey typically looks like so:

<br>
<center>
<div style="width:450px; height=250px">
![](/Users/Connor/Desktop/formstack.png)
</div> 
</center>
<br>

If a user selects "No" then they are presented with the following:

<br>

<center><div style="width:450px; height=600px">
![](/Users/Connor/Desktop/formstack_no.png)
</div>
</center>

<br>
  
These survey responses appear to be a rich source of data regarding the findability of information and services on mass.gov, as well as the overall site's health and user satisfaction.

# Methodology

This section will lay out the methodology for the analysis of Formstack data which will occur daily for all of mass.gov. This analysis will be fed into a dashboard aimed at giving decision makers insights into site performance, funnel performance, 

## Creating Base Data 
First a master data set is created which will contain all responses for all organizations who contribute data. 

The following is the "head" of the formstack data set, which was created by merging all of the individual "Feedback" forms into a single table, removing any personal information, removing ip ranges which are known to be associated with the Commonwealth, and renaming of columns to machine friendly strings: 
\n
```{r}
library(magrittr)
library(ggplot2)
library(foreach)
library(doParallel)

new.cols <- c("submit_time", "info_found", "problem_desc", "site", "content_author",
              "child_content_author", "referrer", "ip_addr", "id", "long", "lat", 
              "browser", "os")

formstack.master <- readr::read_csv('/Users/Connor/Documents/GitHub/bradford/data/formstack/formstack_master.csv') %>%
  dplyr::rename_(.dots = setNames(object = paste0("`", names(.), "`"), nm = new.cols)) %>%
  purrr::map_if(is.character, stringr::str_trim) %>%
  data.frame() %>%
  dplyr::filter(ip_addr != "^(146\\.243\\.\\d{1,3}|170\\.63\\.\\d{1,3}|170\\.154\\.\\d{1,3}|65\\.217\\.255\\.\\d{1,3}|4.36.198.102|65.118.148.102|204.166.193.130|204.130.104.10)",
                info_found %in% c("Yes", "No")) %>%
  dplyr::mutate(info_found = droplevels(info_found))
```

```{r}
head(formstack.master)
```

## Sitewide improvements
The key question Formstack data will assist with is "are the changes made to the new mass.gov an improvement relative to the old site?" This question is answerable with the proposed framework and data, given a few other conditions are met. First, a consistent mapping between old and new content must be created, this will done in the form of page redirects. Second, the feedback module should remain as consistent as possible in the switch between old and new because if, for example, a change in position would increase the average number of people answering in the affirmative we would not want to mix up the effects of that repositioning and the new content itself. There is a situation where point 2 is not as much of an issue, which is getting someone at the leadership level (preferrably Harlan) to estimate a prior distribution for the response rate and modelling the feedback as bayesian inference. 




### Bayesian Inference

In any type of binomial inference we are concerned with estimating some probability that a random variable takes one of two possible values $p(Y)$, in this case an affirmative response. Clearly, this is a system best modelled by a binomial distribution meaning:

$$ 
p(Y) = \binom{N}{Y}\theta^Y(1-\theta)^{(N-Y)}
$$
Where $N$ is the number of bernoulli trials, $Y$ is the random variable representing the outcome of interest, and $\theta$ represents the unkown value bounded by 0 and 1 the equals the true proportion $Y/N$. In english, this means that the distribution models the probability that a person affirms finding the desired content $Y$ times in $N$ trials. Skipping some steps in the interest of brevity we can arrive at the following in a straightforward manner:

$$
p(\theta_{affirm}|Y_{samp},N_{samp}) \propto p(\theta_{affirm})p(Y_{samp}, N_{samp}|\theta_{affirm})
$$
meaning **our derived posterior distribution is proportional to the product of our prior and likelihood!!** More generally this means that our inputs AND our outputs are all distributions. We also have the fortune of leveraging conjugacy which means that when our likelihood and prior are from the same family ([binomial likelihood and beta prior](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)) we get the same kind of distribution out that we put in! 

In order to begin any bayesian inference for binomially distributed data we must specify a prior. This should be done in one of three ways 1) in conjunction with a subject matter expert who can provide an expected $\theta$ and some feedback on the range of values which are likely 2) using what is called an "uninformative prior" which states that all outcomes are equally likely (in the case of a beta distribution $B(\alpha, \beta)$ this takes the values of $\alpha = 1$ $\beta = 1$) or 3) fit an empirical likelihood modelled on data available. 


```{r}
betaplot <- function(a,b){
theta = seq(0,1,0.005)
p_theta = dbeta(theta, a, b)
p <- qplot(theta, p_theta, geom='line')
p <- p + theme_bw()
p <- p + ylab(expression(paste('p(',theta,')', sep = '')))
p <- p + xlab(expression(theta))
return(p)}
```

```{r}
betaplot(1,1)
```

For this analysis framework we will leverage the beta distribution, both because it is conjugate with respect to the binomial distribution and becuase it models our prior beliefs about $\theta$ in a straightforward manner and without any mathematical gymnastics (we simply need to specify $\alpha$ and $\beta$ a priori). The beta distribution is defined as such:
$$
p(\theta) = \theta^{\alpha-1}(1-\theta)^{\beta-1}
$$

This should look familiar as it is quite close to the definition of the binomial distribution above! Again, conjugacy simply means that the product of two functionally identical distributions results in a posterior of the same functional form so: 

$$ 
\theta^{\alpha-1}(1-\theta)^{\beta-1} * \binom{N}{Y}\theta^Y(1-\theta)^{(N-Y)} = \theta^{(Y+\alpha-1)}(1-\theta)^{(N-Y+\beta-1)}
$$
Looking at the result of the above it is clear that we get a beta distribution back as a result of this product. With this posterior we can report the mean, standard deviations, and calculate [bayesian credible intervals](https://en.wikipedia.org/wiki/Credible_interval).

This is an extremely flexible framework that works well with small data where initial summarization may paint a misleading picture. For example, estimating a baseball players batting average is straightforward for someone who has played for many years but for a new player a straight average may paint a very misleading picture. In this example it is more sound to integrate our knowledge of the expected value and distribution of a metric instead of forging ahead as normal and reporting something like a 1.0 or 0.0 as a players average. 

### How we Will Apply

This section will walk through our treatment of Formstack response data within a bayesian framework. 
First and foremost we must specify the parameters of our prior distribution

```{r}
PRIOR.MEAN <- .8
PRIOR.N.SITE <- 1000
PRIOR.N.PAGE <- 10
```
Once we have `formstack.master` in the global environment, per the code in the Creating Base Data section of this document, we can begin creating summarization data frames which will be used to calculate our posteriors for each entry in this summary object. Currently, we are grouping by site (this will be replaced by funnels) and individual pages.

```{r}
response.summary.site <- formstack.master %>%
  dplyr::filter(!is.na(site)) %>%
  dplyr::group_by(site) %>%
  dplyr::summarise(n_affirmative = sum(info_found == "Yes", na.rm = T),
                   n_negative = sum(info_found == "No", na.rm = T),
                   n_total_responses = n()) %>%
  dplyr::mutate(site = droplevels(site)) %>%
  purrr::map_if(is.factor, as.character) %>% 
  data.frame(stringsAsFactors = F)
```

Taking a look at the head of this summary file

```{r}
head(response.summary.site)
```

There are two functions we have defined ourselves which we will use to compute the posterior and it's mean.

```{r}
betaPosterior <- function(df, prior.mean, prior.n, sample.n = "", affirm.n = "") {
  # calculates an approximate beta posterior given the mean and n of a beta prior as well as 
  # the n and n sucesses from a binomial 
  # Args: 
  #   df = a data frame which contains vectors of sample  sizes and number of successful trials
  #   prior.mean = mean of the prior distribution 
  #   prior.n = support for the prior
  #   sample.n = n observations in the treatment population
  #   affirm.n = n successes in treatment population
  # Returns: a data frame which approximates the posterior distribution 
  a = df[[affirm.n]] + (prior.n * prior.mean) - 1
  b = df[[sample.n]] - df[[affirm.n]] + (prior.n * (1 - prior.mean)) - 1
  domain = seq(0, 1, 0.005)
  val = dbeta(domain, a, b)
  data.frame("domain" = domain, "prob_dens" = val)
}
```

```{r}
betaPosteriorMean <- function(df, prior.mean, prior.n, sample.n = "", affirm.n = "") {
  # calculates the mean of the beta posterior given the mean and n of a beta prior as well as 
  # the n and n sucesses from a binomial 
  # Args:
  #   df = a data frame which contains vectors of sample  sizes and number of successful trials
  #   prior.mean = mean of the prior distribution 
  #   prior.n = support for the prior
  #   sample.n = n observations in the treatment population
  #   affirm.n = n successes in treatment population
  # Returns: a float, the mean of the posterior 
  a = df[[affirm.n]] + (prior.n * prior.mean) - 1
  b = df[[sample.n]] - df[[affirm.n]] + (prior.n * (1 - prior.mean)) - 1
  a / (a + b)
}
```

We will call these functions as part of two foreach jobs, one for each of our summary data frames. 

```{r}
cl <- makeForkCluster(4)
registerDoParallel(cl)

response.bayes.site <- foreach(interest.site = iter(response.summary.site$site)) %dopar% {
  interest.pop = response.summary.site[response.summary.site$site == interest.site, ]
  posterior = betaPosterior(interest.pop,  prior.mean = PRIOR.MEAN, 
                             prior.n = PRIOR.N.SITE, 
                             sample.n = "n_total_responses", 
                             affirm.n = "n_affirmative")
  posterior.mean = betaPosteriorMean(interest.pop, prior.mean = PRIOR.MEAN, 
                                       prior.n = PRIOR.N.SITE, 
                                       sample.n = "n_total_responses", 
                                       affirm.n = "n_affirmative")
  cred.int = emdbook::ncredint(pvec = posterior$domain, npost = posterior$prob_dens, 
                    level = .95, tol = 0.01, verbose = FALSE)
  list("site" = interest.site,
       "posterior" = posterior,
       "posterior_mean" = posterior.mean,
       "credible_interval" = cred.int)
}

# stop the cluster
stopCluster(cl)
gc()
```

The above job steps through each row vector in the passed data frame and uses our prior parameters to calculate our posterior, the posterior mean, as well as it's credible interval.

```{r}
response.bayes.site[4]
```
 